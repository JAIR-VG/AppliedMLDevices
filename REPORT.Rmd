---
title: 'Course Project For Predicting Personal Activity '
output:
  html_document: default
  pdf_document: default
date: '2022-04-10'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Using records obtained from Jawbone Up, Nike FuelBand, and Fitbit, we will build a machine learning model to predict personal activity. The dataset contains several measurements, such as accelerometers on the belt, forearm, arm, and dumbbell.
This report is organized as follows: first, exploratory analysis is performed. Next, a data preprocessing step is applied to get a tidy dataset. Then, a machine learning model is built and tested. Finally, conclusions are presented.

## Exploratory Analysis
This section performs several tasks until we get a tidy dataset. The steps are: 1) Download the training and testing datasets, 2) Perform an exploratory data analysis, and 3) Preprocess the dataset.

The training dataset is downloaded from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test dataset is downloaded from

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

Both can be get using the R-command download.file()

Now, we load both datasets

```{r load, echo=TRUE}
training<-read.csv("pml-training.csv", header=TRUE, stringsAsFactors = FALSE)
testing <-read.csv("pml-testing.csv", header=TRUE, stringsAsFactors = FALSE)
```

We show the internal structure of the training set
```{r internalstruc, echo=TRUE}
str(training)
```
The first preprocessing step, in the training and testing dataset is to remove all the variables that are zero variance predictors. Also, as can been observed there are several NA, DIV0 and blank values. The empty values and DIV0 can be seemed as NA, therefore, we set both values to NA. Besides, we compute the columns with NA values.

```{r setNA, echo=TRUE}
library(caret)
idxnzv <-nearZeroVar(training)
training<-training[,-idxnzv]
testing <-testing[,-idxnzv]
training[training == ""] <- NA
training[training == "#DIV/0!"] <- NA
which(colSums(is.na(training))>0)
```
The columns with NA values can be dealt with imputation. However, there are several strategies. Therefore, the columns are removed. Besides, X, user_name and time columns also are removed.Other preprocessing steps are performed, converting string to factors.

```{r removeNA, echo=TRUE}
training <- training[,colSums(is.na(training))==0]
testing <- testing[,colSums(is.na(testing))==0]
training$X <- NULL
training$user_name <- NULL
training$raw_timestamp_part_1<-NULL
training$raw_timestamp_part_2<-NULL
training$cvtd_timestamp<-NULL
training$num_window<-NULL
testing$X <- NULL
testing$user_name <- NULL
testing$raw_timestamp_part_1<-NULL
testing$raw_timestamp_part_2<-NULL
testing$cvtd_timestamp<-NULL
testing$num_window<-NULL
training<-as.data.frame(unclass(training),stringsAsFactors = TRUE)
```

## Experimental Setup and Results

For the experiments, we use an random forest classifier. The training process is performed using a ten fold cross-validation with 50 trees.

```{r expersetup, echo=TRUE}
fitControl<-trainControl(method="cv", number = 10, allowParallel=TRUE)
```

We train the classifier
```{r entrenamiento, echo=TRUE}
modelRF<-train(classe ~ ., data=training, method="rf", trControl=fitControl, ntree=50)
```

We compute the accuracy using the training set

```{r errortra, echo=TRUE}
predicttra<-predict(modelRF,training)
confusionMatrix(predicttra,training$classe)
```

Now we use the test set with the Random Forest trained previously

```{r predtst, echo=TRUE}
predicttst<-predict(modelRF,testing)
predicttst
```

This report can be found in https://rpubs.com/vgarciaj/889816